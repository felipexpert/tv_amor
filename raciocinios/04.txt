Vamos fazer o script GL audios_info.py, segue os tipos relevantes para esta tarefa:

-- GuidoLangUtil.hs

-- Fun√ß√£o principal gen√©rica
glCall :: (ToJSON a, FromJSON b) => GLScript -> a -> IO b
glCall script input = do
    let scriptPath = getGLScriptPath script
        inputJson = encode input

    -- Chama o processo Python
    (Just hin, Just hout, _, _) <- createProcess (proc "python" [scriptPath])
        { std_in = CreatePipe, std_out = CreatePipe }

    -- Envia o JSON para o Python
    BL.hPutStr hin inputJson
    hClose hin

    -- L√™ a resposta
    respostaJson <- BL.hGetContents hout

    -- Decodifica a resposta e retorna
    case eitherDecode respostaJson of
        Right result -> return result
        Left err -> do
            putStrLn "Erro ao decodificar resposta JSON do GuidoLang:"
            putStrLn err
            putStrLn "Resposta recebida:"
            BL.putStrLn respostaJson
            throwIO (userError "Falha ao decodificar JSON de resposta do GuidoLang")

data GLScript
    = GLAudiosInfo
    -- vai ter outros
    deriving (Show, Eq, Generic)

getGLScriptPath :: GLScript -> String
getGLScriptPath GLAudiosInfo = "ModelGL/audios_info.py"

-- AudiosInfo.hs

-- Utiliza para comunicar com o GuidoLang, par√¢metro de envio
newtype AudiosRequest = [AudioRequest] deriving (Show, Eq, Generic)

-- Utiliza para comunicar com o GuidoLang, resultado
newtype AudiosInfo = [AudioInfo] deriving (Show, Eq, Generic)

data AudioInfo = AudioInfo
    -- Caminho do arquivo de √°udio, pode ser um n√∫mero 00001.wav, 00002.wav, etc.
    { aiFilePath :: FilePath 
    -- Dura√ß√£o do √°udio em milissegundos
    , aiDuration :: Int 
    } deriving (Show, Eq, Generic)

data AudioRequest = AudioRequest
    { arText :: Text -- Texto a ser convertido em √°udio
    , arConfig :: AudioRequestConfig -- Configura√ß√µes do √°udio
    } deriving (Show, Eq, Generic)

data AudioRequestConfig = AudioRequestConfig
    { arcVoice :: Text -- Voz a ser utilizada
    -- vai ter mais campos para par√¢metros do timbre da voz
    } deriving (Show, Eq, Generic)

-- Fun√ß√£o para solicitar √°udios ao GuidoLang
requestAudiosIO :: AudiosRequest -> IO AudiosInfo
requestAudiosIO ar = do 
    -- Aqui voc√™ implementaria a l√≥gica para enviar a requisi√ß√£o ao GuidoLang
    -- e receber a resposta com as informa√ß√µes dos √°udios.
    
-- script python de exemplo audio_v4.py 

import re
import asyncio
import edge_tts
from pydub import AudioSegment
import os
import json
import ast

RE_CHAR_LABEL = re.compile(r"\[char_label:([a-zA-Z0-9_]+)\]")
RE_COMMAND_JSON = re.compile(r"\{[^{}]+\}")

async def gerar_audio(texto, nome_arquivo, voz="pt-BR-AntonioNeural"):
    communicate = edge_tts.Communicate(texto, voice=voz)
    with open(nome_arquivo, "wb") as f:
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                f.write(chunk["data"])

def parsear_bloco(texto):
    """
    Divide o texto por personagens e comandos embutidos.
    Retorna lista de dicion√°rios: {char_label, tipo: 'fala' ou 'comando', conteudo}
    """
    blocos = []
    partes = RE_CHAR_LABEL.split(texto)
    # partes = [texto_antes, char1, fala1, char2, fala2, ...]
    for i in range(1, len(partes), 2):
        char = partes[i].strip()
        fala_e_comandos = partes[i+1]
        
        pos = 0
        comandos = list(RE_COMMAND_JSON.finditer(fala_e_comandos))

        for cmd_match in comandos:
            start, end = cmd_match.span()
            fala = fala_e_comandos[pos:start].strip()
            if fala:
                blocos.append({'char_label': char, 'tipo': 'fala', 'conteudo': fala})
            comando = ast.literal_eval(cmd_match.group())
            comando['char_label'] = comando.get('char_label', char)
            blocos.append({'tipo': 'comando', 'conteudo': comando})
            pos = end

        # Pega o resto depois do √∫ltimo comando, se houver
        resto = fala_e_comandos[pos:].strip()
        if resto:
            blocos.append({'char_label': char, 'tipo': 'fala', 'conteudo': resto})

    return blocos

async def processar_blocos(blocos, voz_default="pt-BR-AntonioNeural"):
    tempo_acumulado = 0.0
    eventos = []
    arquivos = []

    # Contador separado para nomear os arquivos de √°udio
    contador_audio = 0  

    for idx, bloco in enumerate(blocos):
        if bloco['tipo'] == 'fala':
            texto = bloco['conteudo']
            char = bloco['char_label']
            nome_arquivo = f"{contador_audio}_{char}.mp3"
            print(f"[{tempo_acumulado:.2f}s] MP3-{contador_audio} fala: '{texto[:30]}...'")

            await gerar_audio(texto, nome_arquivo, voz=voz_default)
            audio = AudioSegment.from_file(nome_arquivo)
            duracao = audio.duration_seconds
            arquivos.append(nome_arquivo)

            eventos.append({
                'tipo': 'fala',
                'char_label': char,
                'arquivo': nome_arquivo,
                'inicio': tempo_acumulado,
                'fim': tempo_acumulado + duracao
            })

            tempo_acumulado += duracao
            
            # Incrementa apenas quando gera √°udio
            contador_audio += 1

        elif bloco['tipo'] == 'comando':
            comando = bloco['conteudo']
            tipo = comando['type']
            char = comando.get('char_label', 'desconhecido')

            if tipo == 'pause':
                dur = float(comando.get('dur', 0.5))
                print(f"[{tempo_acumulado:.2f}s] MP3-{contador_audio} pausa de {dur:.1f}s")
                audio = AudioSegment.silent(duration=int(dur * 1000))
                nome_arquivo = f"{contador_audio}_pause.mp3"
                audio.export(nome_arquivo, format="mp3")
                arquivos.append(nome_arquivo)

                tempo_acumulado += dur

                # Incrementa apenas quando gera √°udio
                contador_audio += 1

            else:
                print(f"[{tempo_acumulado:.2f}s] Comando '{tipo}' para {char}")
                eventos.append({
                    'tipo': 'comando',
                    'acao': tipo,
                    'char_label': char,
                    'tempo': tempo_acumulado
                })

    return arquivos, eventos

def concatenar_audios(lista_arquivos, arquivo_saida="saida_final.mp3"):
    combined = AudioSegment.empty()
    for arquivo in lista_arquivos:
        audio = AudioSegment.from_file(arquivo)
        combined += audio
    combined.export(arquivo_saida, format="mp3")
    return arquivo_saida

async def main(texto):
    blocos = parsear_bloco(texto)
    arquivos, eventos = await processar_blocos(blocos)

    arquivo_final = concatenar_audios(arquivos)
    print(f"\n√Åudio final gerado: {arquivo_final}\n")

    print("üîä Eventos de fala e comandos:")
    for evento in eventos:
        print(json.dumps(evento, indent=2))

    # Os arquivos individuais de √°udio ser√£o mantidos para uso na aplica√ß√£o
    print("\nArquivos individuais salvos:")
    for f in arquivos:
        print(f" - {f}")

if __name__ == "__main__":
    texto_exemplo = """
    [char_label:char_felipe]Ol√° Gisele{'type':'wave','char_label':'char_felipe'}{'type':'wave','char_label':'char_gisele'}{'type':'pause','dur':'0.5'}Tudo bem por a√≠?
    [char_label:char_gisele]Ol√° Felipe! Tudo √≥timo!
    """

    asyncio.run(main(texto_exemplo))

